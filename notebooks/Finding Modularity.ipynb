{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies ####\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "import cortex # This dependency is pycortex, which enables the plotting of flatmaps. It can be disabled.\n",
    "from cvxopt import matrix, solvers # Only necessary for the stacked model.\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # Only necessary for feature extraction.\n",
    "import subprocess\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "# Repository imports\n",
    "from ridge_utils.ridge import bootstrap_ridge\n",
    "import ridge_utils.npp\n",
    "from ridge_utils.util import make_delayed\n",
    "from ridge_utils.dsutils import make_word_ds\n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "from ridge_utils.tokenization_helpers import generate_efficient_feat_dicts_opt\n",
    "from ridge_utils.tokenization_helpers import convert_to_feature_mats_opt\n",
    "\n",
    "# Topic model imports\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer # For generating embeddings\n",
    "from sklearn.decomposition import PCA # To speed up the UMAP\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import en_core_web_sm\n",
    "from bertopic.representation import PartOfSpeech, KeyBERTInspired, MaximalMarginalRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths for the the story data and FMRI data\n",
    "grids_path = \"../data/story_data/grids_huge.jbl\"\n",
    "trfiles_path = \"../data/story_data/trfiles_huge.jbl\"\n",
    "\n",
    "## Paths for the topic encoder\n",
    "model_dir = \"../models\"\n",
    "embeddings_dir = \"../embeddings\"\n",
    "\n",
    "## If there are any pre-trained models you'd like to use\n",
    "model_path = None\n",
    "\n",
    "# If embeddings have been pre-computed\n",
    "embeddings_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download cortex data\n",
    "Here we automate the download of the brain models from open-neuro. It uses curl to download the files, and then sets the cortex path to be the correct location for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b914e8a2a246e8b6dcdf882ab0259a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pycortex database\n",
       "  Subjects:\n",
       "   UTS01\n",
       "   UTS02\n",
       "   UTS03"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycortex_download_script = \"../ds003020-2.2.0.sh\"\n",
    "pycortex_dir = '../pycortex-db'\n",
    "\n",
    "# Select which subjects to download (full list is ['UTS01', 'UTS02','UTS03','UTS04','UTS05','UTS06','UTS07','UTS08'] ) \n",
    "subjects = ['UTS01', 'UTS02','UTS03']\n",
    "\n",
    "with open(pycortex_download_script, 'r') as f:\n",
    "    pbar = tqdm(f)\n",
    "    for line in pbar:\n",
    "        if 'derivative/pycortex-db/UTS' in line:\n",
    "            for subject in subjects:\n",
    "                if subject in line:\n",
    "                    # Construct the output command\n",
    "                    output_command = line.replace(' derivative/pycortex-db/', ' ' + pycortex_dir + os.sep)\n",
    "                    \n",
    "                    # Extract the output file path from the curl command\n",
    "                    # Assuming the output path is specified with -o option in the curl command\n",
    "                    parts = output_command.split()\n",
    "                    output_file_path = None\n",
    "                    if '-o' in parts:\n",
    "                        output_file_index = parts.index('-o') + 1\n",
    "                        output_file_path = parts[output_file_index]\n",
    "                    \n",
    "                    # Check if the file exists\n",
    "                    if output_file_path and not os.path.exists(output_file_path):\n",
    "                        subprocess.run(output_command, shell=True)\n",
    "                    else:\n",
    "                        pbar.set_description(f\"File {output_file_path} already exists. Skipping download.\")\n",
    "\n",
    "# This is your new filestore path\n",
    "new_filestore_path = os.path.join(os.getcwd(), pycortex_dir)\n",
    "cortex.options.config.set('basic', 'filestore', new_filestore_path)\n",
    "# Set the new filestore path\n",
    "cortex.db.filestore = cortex.options.config.get('basic', 'filestore')\n",
    "cortex.db.reload_subjects()\n",
    "cortex.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Setup\n",
    "\n",
    "Sets up the GPU if there is one there. Biggest benefit will be on CUDA systems, some benefits exist for MacOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use MPS if available\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Fallback to CUDA or CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../test_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
